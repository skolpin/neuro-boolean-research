{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ec5eb2-3cbe-4652-9d78-2bb72d039795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e93260-1815-4f14-8723-b6ce10d3ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec2bin(x, n=7):\n",
    "    \"\"\"\n",
    "    creating a binary list of integer non-negative x\n",
    "    \"\"\"\n",
    "    u = 2 ** n - 1\n",
    "    x = int(x)\n",
    "    assert x >= 0, 'Input value x must be non-negative'\n",
    "    assert x <= u, f'Input value x with n = {n} must be less than {u}'\n",
    "    \n",
    "    y = []\n",
    "    if x == 0:\n",
    "        for i in range(n):\n",
    "            y.append(0)\n",
    "    else:\n",
    "        while x != 1:\n",
    "            y.append(x % 2)\n",
    "            x = x // 2\n",
    "        y.append(x)\n",
    "        delta = n - len(y)\n",
    "        for i in range(delta):\n",
    "            y.append(0)\n",
    "        y.reverse()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db837d9c-04b2-41e5-8ee4-e615959b4efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_X(n_inputs):\n",
    "    \"\"\"\n",
    "    for given number of variables returns\n",
    "    all binary combinations of these variables\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    for i in range(2**n_inputs):\n",
    "        X += [dec2bin(i, n=n_inputs)]\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a2cedd-519d-4d14-bce2-4e612aa608d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_boolfunc(n_inputs):\n",
    "    \"\"\"\n",
    "    for given number of variables returns\n",
    "    the truth table, where output is random binary vector\n",
    "    \"\"\"\n",
    "    X = get_all_X(n_inputs)\n",
    "    y = np.random.randint(0, 2, size=(2**n_inputs, 1))\n",
    "    return X, y\n",
    "   \n",
    "def _and(n_inputs=2):\n",
    "    \"\"\"\n",
    "    for given number of variables returns\n",
    "    the truth table of AND logical gate\n",
    "    \"\"\"\n",
    "    X = get_all_X(n_inputs)\n",
    "    y = np.append(\n",
    "        np.zeros(shape=(2 ** n_inputs - 1, 1), dtype=int),\n",
    "        np.array([[1]]),\n",
    "        axis=0\n",
    "    )\n",
    "    return X, y\n",
    "    \n",
    "def _or(n_inputs=2):\n",
    "    \"\"\"\n",
    "    for given number of variables returns\n",
    "    the truth table of OR logical gate\n",
    "    \"\"\"\n",
    "    X = get_all_X(n_inputs)\n",
    "    y = np.append(\n",
    "        np.array([[0]]),\n",
    "        np.ones(shape=(2 ** n_inputs - 1, 1), dtype=int),\n",
    "        axis=0\n",
    "    )\n",
    "    return X, y\n",
    "\n",
    "def _xor(n_inputs=2):\n",
    "    \"\"\"\n",
    "    for given number of variables returns\n",
    "    the truth table of XOR logical gate\n",
    "    \"\"\"\n",
    "    X = get_all_X(n_inputs)\n",
    "    y = (np.sum(X, axis=1) % 2).reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "def to_dataframe(X, y):\n",
    "    \"\"\"\n",
    "    for the truth table in form of two arrays \n",
    "    X [2 ** n_inputs, n_inputs] and y [2 ** n_inputs, 1]\n",
    "    combine it to the form of Pandas DataFrame\n",
    "    \"\"\"\n",
    "    data=np.concatenate((X, y), axis=1)\n",
    "    n_inputs = X.shape[1]\n",
    "    return pd.DataFrame(data=data, columns=[f'x{i}' for i in range(n_inputs, 0, -1)] + ['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79d825d5-cecf-4112-ade4-df71d38a5f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.99 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x2</th>\n",
       "      <th>x1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x2  x1  y\n",
       "0   0   0  0\n",
       "1   0   1  1\n",
       "2   1   0  1\n",
       "3   1   1  0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n = 2\n",
    "set_random_seed(23) # just for get a complex random function\n",
    "# X, y = random_boolfunc(n_inputs=n)\n",
    "X, y = _xor(2)\n",
    "to_dataframe(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e34c8fc-4244-4097-9ff5-cb6caad866fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = torch.Tensor(X), torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1415d0e8-0837-47da-b1b7-ce2121b95b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(nn.Module):\n",
    "    def __init__(self, n_inputs, activation=nn.Sigmoid()):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(n_inputs, 1)\n",
    "        self.activation = activation\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b18cfd-6a88-4ba1-b03c-c3332a7573db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, optimizer, criterion, epochs, verbose=True):\n",
    "    \n",
    "    log_epoch = epochs // 10\n",
    "    for i in range(1, epochs + 1):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if verbose and i % log_epoch == 0:\n",
    "            print(f'epoch {i}: loss {loss:.2f}')\n",
    "\n",
    "def step(x):\n",
    "    return torch.heaviside(x - 0.5, torch.tensor([[1.]]))\n",
    "\n",
    "def check(model, X, y):\n",
    "    out = model(X)\n",
    "    step_out = step(out)\n",
    "    mask = (step_out != y)[:,0]  \n",
    "    \n",
    "    if any(mask):\n",
    "        wrong_ans_numbers = [i for i in range(mask.shape[0]) if mask[i].item()]\n",
    "        print(f'{type(model).__name__} gives wrong answers for samples {wrong_ans_numbers}')\n",
    "        return X[mask], y[mask]\n",
    "    else:\n",
    "        print('Success!')\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8076a7fc-9e0b-48ab-9a75-e3c99bb7429b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500: loss 0.69\n",
      "epoch 1000: loss 0.69\n",
      "epoch 1500: loss 0.69\n",
      "epoch 2000: loss 0.69\n",
      "epoch 2500: loss 0.69\n",
      "epoch 3000: loss 0.69\n",
      "epoch 3500: loss 0.69\n",
      "epoch 4000: loss 0.69\n",
      "epoch 4500: loss 0.69\n",
      "epoch 5000: loss 0.69\n"
     ]
    }
   ],
   "source": [
    "model = Neuron(n_inputs=n)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "train(model, X, y, optimizer, criterion, epochs=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fcb40d52-6b8f-4777-b193-09860423363d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron gives wrong answers for samples [0, 3]\n"
     ]
    }
   ],
   "source": [
    "X_new, y_new = check(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07229066-7fd3-4a62-9794-3de127efeb76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500: loss 0.00\n",
      "epoch 1000: loss 0.00\n",
      "epoch 1500: loss 0.00\n",
      "epoch 2000: loss 0.00\n",
      "epoch 2500: loss 0.00\n",
      "epoch 3000: loss 0.00\n",
      "epoch 3500: loss 0.00\n",
      "epoch 4000: loss 0.00\n",
      "epoch 4500: loss 0.00\n",
      "epoch 5000: loss 0.00\n"
     ]
    }
   ],
   "source": [
    "model2 = Neuron(n_inputs=n)\n",
    "\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr = 0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "train(model2, X_new, y_new, optimizer, criterion, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cc0a0467-8d86-4c41-8a59-bef47f70c814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "X_new2, y_new2 = check(model2, X_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a635c85e-69f4-47b8-b70f-4a137fa53568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# https://github.com/pytorch/pytorch/issues/36459#:~:text=Here%27s%20my%20definition%3A\n",
    "\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self, base_models : list):\n",
    "        super().__init__()\n",
    "        self.base_models = nn.ModuleList(deepcopy(base_models))\n",
    "        \n",
    "        # for model in self.base_models:\n",
    "        #     for param in model.parameters():\n",
    "        #         param.requires_grad = False\n",
    "        \n",
    "        self.n_hidden = len(base_models)\n",
    "        self.fc = nn.Linear(self.n_hidden, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        self.merge = lambda x: torch.cat(x, dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden_out = self.merge([module(x) for module in self.base_models])\n",
    "        out = self.activation(self.fc(hidden_out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a51e9cee-cedd-4296-b7f1-11c301a8772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500: loss 0.29\n",
      "epoch 1000: loss 0.04\n",
      "epoch 1500: loss 0.02\n",
      "epoch 2000: loss 0.01\n",
      "epoch 2500: loss 0.01\n",
      "epoch 3000: loss 0.00\n",
      "epoch 3500: loss 0.00\n",
      "epoch 4000: loss 0.00\n",
      "epoch 4500: loss 0.00\n",
      "epoch 5000: loss 0.00\n"
     ]
    }
   ],
   "source": [
    "big_model = BigModel([model, model2])\n",
    "\n",
    "optimizer = torch.optim.Adam(big_model.parameters(), lr = 0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "train(big_model, X, y, optimizer, criterion, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ecd01678-225b-4f86-a1e0-02a2060b9752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(big_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7ea8875-eee8-4f36-9d6b-55140d8f5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# если не учить веса базовых нейронов, нифига не учится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9eb7ba-d4f1-4fdc-ac55-5a58b9829d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c450d6ea-ba3c-4d41-b257-3541224bfd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n",
      "Success!\n",
      "Success!\n",
      "Sequential gives wrong answers for samples [2, 3]\n",
      "Sequential gives wrong answers for samples [1, 3]\n",
      "Success!\n",
      "Sequential gives wrong answers for samples [2, 3]\n",
      "Success!\n",
      "Sequential gives wrong answers for samples [3]\n",
      "Success!\n",
      "{'success': 6, 'fail': 4}\n"
     ]
    }
   ],
   "source": [
    "counter = {'success':0, 'fail':0}\n",
    "\n",
    "for _ in range(10):\n",
    "\n",
    "    mlp = nn.Sequential(\n",
    "        nn.Linear(n,2),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(2,1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(mlp.parameters(), lr = 0.01)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    train(mlp, X, y, optimizer, criterion, epochs=5000, verbose=False)\n",
    "\n",
    "    if check(mlp, X, y)[0] is None:\n",
    "        counter['success'] += 1\n",
    "    else:\n",
    "        counter['fail'] += 1\n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8afe7976-2ff4-467c-bb05-86770720a5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': 7, 'fail': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bfa71-a3e9-4148-a6d8-482aa827f889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0995fa10-6298-45cf-a7fd-382d7540612e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x4</th>\n",
       "      <th>x3</th>\n",
       "      <th>x2</th>\n",
       "      <th>x1</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x4  x3  x2  x1  y\n",
       "0    0   0   0   0  0\n",
       "1    0   0   0   1  1\n",
       "2    0   0   1   0  1\n",
       "3    0   0   1   1  0\n",
       "4    0   1   0   0  1\n",
       "5    0   1   0   1  0\n",
       "6    0   1   1   0  0\n",
       "7    0   1   1   1  1\n",
       "8    1   0   0   0  1\n",
       "9    1   0   0   1  0\n",
       "10   1   0   1   0  0\n",
       "11   1   0   1   1  1\n",
       "12   1   1   0   0  0\n",
       "13   1   1   0   1  1\n",
       "14   1   1   1   0  1\n",
       "15   1   1   1   1  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 4\n",
    "set_random_seed(23) # just for get a complex random function\n",
    "# X, y = random_boolfunc(n_inputs=n)\n",
    "X, y = _xor(n)\n",
    "display(to_dataframe(X, y))\n",
    "X, y = torch.Tensor(X), torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5f6f478d-243b-4740-a679-f2ad989233ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 500: loss 0.69\n",
      "epoch 1000: loss 0.69\n",
      "epoch 1500: loss 0.69\n",
      "epoch 2000: loss 0.69\n",
      "epoch 2500: loss 0.69\n",
      "epoch 3000: loss 0.69\n",
      "epoch 3500: loss 0.69\n",
      "epoch 4000: loss 0.69\n",
      "epoch 4500: loss 0.69\n",
      "epoch 5000: loss 0.69\n",
      "Neuron gives wrong answers for samples [0, 3, 5, 6, 9, 10, 12, 15]\n",
      "epoch 500: loss 0.03\n",
      "epoch 1000: loss 0.01\n",
      "epoch 1500: loss 0.01\n",
      "epoch 2000: loss 0.00\n",
      "epoch 2500: loss 0.00\n",
      "epoch 3000: loss 0.00\n",
      "epoch 3500: loss 0.00\n",
      "epoch 4000: loss 0.00\n",
      "epoch 4500: loss 0.00\n",
      "epoch 5000: loss 0.00\n",
      "Success!\n",
      "epoch 2000: loss 0.45\n",
      "epoch 4000: loss 0.45\n",
      "epoch 6000: loss 0.45\n",
      "epoch 8000: loss 0.45\n",
      "epoch 10000: loss 0.45\n",
      "epoch 12000: loss 0.45\n",
      "epoch 14000: loss 0.45\n",
      "epoch 16000: loss 0.45\n",
      "epoch 18000: loss 0.45\n",
      "epoch 20000: loss 0.45\n",
      "BigModel gives wrong answers for samples [7, 11, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "neurons = []\n",
    "current_neuron = Neuron(n_inputs=n)\n",
    "\n",
    "optimizer = torch.optim.Adam(current_neuron.parameters(), lr = 0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "train(current_neuron, X, y, optimizer, criterion, epochs=5000)\n",
    "\n",
    "X_new, y_new = check(current_neuron, X, y)\n",
    "\n",
    "if X_new is None:\n",
    "    result_model = current_neuron\n",
    "    print(result_model)\n",
    "\n",
    "else:\n",
    "    neurons.append(deepcopy(current_neuron))\n",
    "    \n",
    "    while X_new is not None:\n",
    "        \n",
    "        current_neuron = Neuron(n_inputs=n)\n",
    "\n",
    "        optimizer = torch.optim.Adam(current_neuron.parameters(), lr = 0.01)\n",
    "        criterion = torch.nn.BCELoss()\n",
    "\n",
    "        train(current_neuron, X_new, y_new, optimizer, criterion, epochs=5000)\n",
    "\n",
    "        X_new, y_new = check(current_neuron, X_new, y_new)\n",
    "        \n",
    "        neurons.append(deepcopy(current_neuron))\n",
    "    \n",
    "    # neurons.append(Neuron(n_inputs=n))\n",
    "    # neurons.append(Neuron(n_inputs=n))\n",
    "    \n",
    "    big_model = BigModel(neurons)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(big_model.parameters(), lr = 0.01)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    train(big_model, X, y, optimizer, criterion, epochs=20000)\n",
    "    \n",
    "    check(big_model, X, y)\n",
    "    \n",
    "    result_model = deepcopy(big_model)\n",
    "    \n",
    "# print(result_model)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "961c59ab-30f0-4bf3-8837-056ddea5af84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigModel gives wrong answers for samples [7, 11, 13, 14]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 1., 0., 1.],\n",
       "         [1., 1., 1., 0.]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(result_model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5aa16a1d-981a-4c1c-9131-b1020adb5d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigModel(\n",
       "  (base_models): ModuleList(\n",
       "    (0): Neuron(\n",
       "      (fc): Linear(in_features=4, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "    (1): Neuron(\n",
       "      (fc): Linear(in_features=4, out_features=1, bias=True)\n",
       "      (activation): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99644c43-782e-4443-84fd-f55fc3a27a60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
